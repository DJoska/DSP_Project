Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 126, 171, 32)      320
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 124, 169, 64)      18496
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 62, 84, 64)        0
_________________________________________________________________
dropout (Dropout)            (None, 62, 84, 64)        0
_________________________________________________________________
flatten (Flatten)            (None, 333312)            0
_________________________________________________________________
dense (Dense)                (None, 128)               42664064
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_1 (Dense)              (None, 11)                1419
=================================================================

tiny (70)

Total params: 42,684,299
Trainable params: 42,684,299
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
2020-06-25 21:42:48.736431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-25 21:42:49.073393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-25 21:42:50.451320: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-06-25 21:42:51.136288: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-25 21:42:51.144307: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-25 21:42:51.368461: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-25 21:42:51.376257: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
1/1 [==============================] - 0s 1ms/step - loss: 20.4376 - accuracy: 0.0571
Epoch 2/20
1/1 [==============================] - 0s 0s/step - loss: 24.5562 - accuracy: 0.5714
Epoch 3/20
1/1 [==============================] - 0s 1ms/step - loss: 10.7246 - accuracy: 0.7000
Epoch 4/20
1/1 [==============================] - 0s 1ms/step - loss: 7.1190 - accuracy: 0.7714
Epoch 5/20
1/1 [==============================] - 0s 0s/step - loss: 2.7438 - accuracy: 0.8429
Epoch 6/20
1/1 [==============================] - 0s 1ms/step - loss: 6.0704 - accuracy: 0.8714
Epoch 7/20
1/1 [==============================] - 0s 0s/step - loss: 0.5518 - accuracy: 0.9286
Epoch 8/20
1/1 [==============================] - 0s 0s/step - loss: 0.4747 - accuracy: 0.9286
Epoch 9/20
1/1 [==============================] - 0s 1ms/step - loss: 4.3354 - accuracy: 0.9000
Epoch 10/20
1/1 [==============================] - 0s 0s/step - loss: 0.0681 - accuracy: 0.9714
Epoch 11/20
1/1 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.9429
Epoch 12/20
1/1 [==============================] - 0s 0s/step - loss: 0.6975 - accuracy: 0.9571
Epoch 13/20
1/1 [==============================] - 0s 1ms/step - loss: 27.3344 - accuracy: 0.9286
Epoch 14/20
1/1 [==============================] - 0s 0s/step - loss: 0.6440 - accuracy: 0.9857
Epoch 15/20
1/1 [==============================] - 0s 0s/step - loss: 1.1770 - accuracy: 0.9714
Epoch 16/20
1/1 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.9571
Epoch 17/20
1/1 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 1.0000
Epoch 18/20
1/1 [==============================] - 0s 0s/step - loss: 0.0148 - accuracy: 1.0000
Epoch 19/20
1/1 [==============================] - 0s 0s/step - loss: 0.0810 - accuracy: 0.9857
Epoch 20/20
1/1 [==============================] - 0s 0s/step - loss: 6.0515 - accuracy: 0.9571
26/26 [==============================] - 1s 22ms/step - loss: 416.4231 - accuracy: 0.2861
Accuracy: 28.61
Data collection time:  69.656 s
Training time:  7.3951 s
Testing time:  1.0984 s

818 (small)
Total params: 42,684,299
Trainable params: 42,684,299
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
2020-06-25 21:46:32.544467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-25 21:46:32.872680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-25 21:46:34.170432: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-06-25 21:46:34.588151: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-25 21:46:34.596316: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-25 21:46:34.969609: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-25 21:46:34.977753: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
9/9 [==============================] - 1s 163ms/step - loss: 92.8073 - accuracy: 0.3117
Epoch 2/20
9/9 [==============================] - 1s 108ms/step - loss: 19.4880 - accuracy: 0.4804
Epoch 3/20
9/9 [==============================] - 1s 109ms/step - loss: 4.4864 - accuracy: 0.5856
Epoch 4/20
9/9 [==============================] - 1s 109ms/step - loss: 1.8329 - accuracy: 0.6626
Epoch 5/20
9/9 [==============================] - 1s 109ms/step - loss: 1.1004 - accuracy: 0.7237
Epoch 6/20
9/9 [==============================] - 1s 109ms/step - loss: 0.7594 - accuracy: 0.7665
Epoch 7/20
9/9 [==============================] - 1s 109ms/step - loss: 0.5226 - accuracy: 0.8509
Epoch 8/20
9/9 [==============================] - 1s 109ms/step - loss: 0.3879 - accuracy: 0.8851
Epoch 9/20
9/9 [==============================] - 1s 109ms/step - loss: 0.3587 - accuracy: 0.8875
Epoch 10/20
9/9 [==============================] - 1s 109ms/step - loss: 0.2539 - accuracy: 0.9218
Epoch 11/20
9/9 [==============================] - 1s 109ms/step - loss: 0.2054 - accuracy: 0.9401
Epoch 12/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1546 - accuracy: 0.9560
Epoch 13/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1466 - accuracy: 0.9523
Epoch 14/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1683 - accuracy: 0.9487
Epoch 15/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1657 - accuracy: 0.9584
Epoch 16/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1100 - accuracy: 0.9743
Epoch 17/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1282 - accuracy: 0.9743
Epoch 18/20
9/9 [==============================] - 1s 109ms/step - loss: 0.1014 - accuracy: 0.9719
Epoch 19/20
9/9 [==============================] - 1s 109ms/step - loss: 0.0791 - accuracy: 0.9792
Epoch 20/20
9/9 [==============================] - 1s 108ms/step - loss: 0.1594 - accuracy: 0.9792
3/3 [==============================] - 0s 49ms/step - loss: 6.9570 - accuracy: 0.7429
Accuracy: 74.29
Data collection time:  69.7904 s
Training time:  28.1746 s
Testing time:  0.6662 s

1344 samples training
507 samplse testing

Total params: 42,684,299
Trainable params: 42,684,299
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
2020-06-24 16:07:33.325807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-24 16:07:33.698083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-24 16:07:34.964857: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-06-24 16:07:35.418102: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 16:07:35.426425: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
13/14 [==========================>...] - ETA: 0s - loss: 99.4548 - accuracy: 0.2385 2020-06-24 16:07:38.848000: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 16:07:38.856055: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 16:07:39.072492: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 16:07:39.080291: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
14/14 [==============================] - 3s 207ms/step - loss: 96.4165 - accuracy: 0.2366
Epoch 2/20
14/14 [==============================] - 2s 131ms/step - loss: 11.5909 - accuracy: 0.3333
Epoch 3/20
14/14 [==============================] - 2s 130ms/step - loss: 2.2654 - accuracy: 0.3304
Epoch 4/20
14/14 [==============================] - 2s 130ms/step - loss: 1.7395 - accuracy: 0.3780
Epoch 5/20
14/14 [==============================] - 2s 131ms/step - loss: 1.4822 - accuracy: 0.4447
Epoch 6/20
14/14 [==============================] - 2s 131ms/step - loss: 1.2988 - accuracy: 0.5304
Epoch 7/20
14/14 [==============================] - 2s 131ms/step - loss: 1.1434 - accuracy: 0.5780
Epoch 8/20
14/14 [==============================] - 2s 130ms/step - loss: 0.9948 - accuracy: 0.6484
Epoch 9/20
14/14 [==============================] - 2s 131ms/step - loss: 0.8163 - accuracy: 0.6989
Epoch 10/20
14/14 [==============================] - 2s 131ms/step - loss: 0.8001 - accuracy: 0.7421
Epoch 11/20
14/14 [==============================] - 2s 133ms/step - loss: 0.7276 - accuracy: 0.7670
Epoch 12/20
14/14 [==============================] - 2s 130ms/step - loss: 0.6153 - accuracy: 0.8066
Epoch 13/20
14/14 [==============================] - 2s 131ms/step - loss: 0.5271 - accuracy: 0.8205
Epoch 14/20
14/14 [==============================] - 2s 131ms/step - loss: 0.5016 - accuracy: 0.8447
Epoch 15/20
14/14 [==============================] - 2s 131ms/step - loss: 0.4474 - accuracy: 0.8557
Epoch 16/20
14/14 [==============================] - 2s 130ms/step - loss: 0.4257 - accuracy: 0.8608
Epoch 17/20
14/14 [==============================] - 2s 131ms/step - loss: 0.3773 - accuracy: 0.8813
Epoch 18/20
14/14 [==============================] - 2s 131ms/step - loss: 0.3818 - accuracy: 0.8769
Epoch 19/20
14/14 [==============================] - 2s 130ms/step - loss: 0.3839 - accuracy: 0.8857
Epoch 20/20
14/14 [==============================] - 2s 129ms/step - loss: 0.3258 - accuracy: 0.8938
16/16 [==============================] - 0s 31ms/step - loss: 1.5482 - accuracy: 0.7219
Accuracy: 72.19
Data collection time:  203.8694 s
Training time:  45.947 s
Testing time:  0.0 s

whole valid set, split 60/40 training
whole test set testing

Total params: 42,684,299
Trainable params: 42,684,299
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
2020-06-24 20:14:22.749009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-24 20:14:26.223518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-24 20:14:31.328607: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-06-24 20:14:32.923422: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 20:14:32.935312: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 20:14:33.382789: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 20:14:33.393739: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
77/77 [==============================] - 12s 150ms/step - loss: 18.5439 - accuracy: 0.3032
Epoch 2/20
77/77 [==============================] - 11s 145ms/step - loss: 1.3792 - accuracy: 0.5158
Epoch 3/20
77/77 [==============================] - 11s 146ms/step - loss: 0.9923 - accuracy: 0.6717
Epoch 4/20
77/77 [==============================] - 11s 144ms/step - loss: 0.7101 - accuracy: 0.7727
Epoch 5/20
77/77 [==============================] - 11s 143ms/step - loss: 0.5436 - accuracy: 0.8222
Epoch 6/20
77/77 [==============================] - 11s 145ms/step - loss: 0.4503 - accuracy: 0.8560
Epoch 7/20
77/77 [==============================] - 14s 183ms/step - loss: 0.3936 - accuracy: 0.8743
Epoch 8/20
77/77 [==============================] - 12s 157ms/step - loss: 0.3121 - accuracy: 0.9040
Epoch 9/20
77/77 [==============================] - 12s 154ms/step - loss: 0.2896 - accuracy: 0.9169
Epoch 10/20
77/77 [==============================] - 12s 155ms/step - loss: 0.2488 - accuracy: 0.9277
Epoch 11/20
77/77 [==============================] - 12s 155ms/step - loss: 0.2197 - accuracy: 0.9336
Epoch 12/20
77/77 [==============================] - 12s 155ms/step - loss: 0.2102 - accuracy: 0.9414
Epoch 13/20
77/77 [==============================] - 12s 159ms/step - loss: 0.2176 - accuracy: 0.9477
Epoch 14/20
77/77 [==============================] - 12s 161ms/step - loss: 0.1684 - accuracy: 0.9494
Epoch 15/20
77/77 [==============================] - 12s 159ms/step - loss: 0.1510 - accuracy: 0.9548
Epoch 16/20
77/77 [==============================] - 12s 157ms/step - loss: 0.1597 - accuracy: 0.9541
Epoch 17/20
77/77 [==============================] - 12s 161ms/step - loss: 0.1375 - accuracy: 0.9596
Epoch 18/20
77/77 [==============================] - 12s 158ms/step - loss: 0.1238 - accuracy: 0.9646
Epoch 19/20
77/77 [==============================] - 12s 158ms/step - loss: 0.1364 - accuracy: 0.9581
Epoch 20/20
77/77 [==============================] - 12s 158ms/step - loss: 0.1080 - accuracy: 0.9678
159/159 [==============================] - 3s 21ms/step - loss: 0.4173 - accuracy: 0.9478
Accuracy: 94.78
Data collection time:  997.413 s
Training time:  282.6699 s
Testing time:  6.7444 s

whole valid set training
whole test set testing

Epoch 1/20
2020-06-24 16:36:31.582101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-24 16:36:34.538663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-24 16:36:36.936318: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-06-24 16:36:38.346576: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 16:36:38.356193: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
126/127 [============================>.] - ETA: 0s - loss: 10.5355 - accuracy: 0.33582020-06-24 16:36:58.884234: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.48GiB with freed_by_count=0. The 
caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-06-24 16:36:58.892794: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
127/127 [==============================] - 20s 158ms/step - loss: 10.4801 - accuracy: 0.3367
Epoch 2/20
127/127 [==============================] - 19s 146ms/step - loss: 1.2241 - accuracy: 0.5551
Epoch 3/20
127/127 [==============================] - 18s 143ms/step - loss: 0.8376 - accuracy: 0.7102
Epoch 4/20
127/127 [==============================] - 18s 143ms/step - loss: 0.5948 - accuracy: 0.7903
Epoch 5/20
127/127 [==============================] - 18s 144ms/step - loss: 0.4485 - accuracy: 0.8535
Epoch 6/20
127/127 [==============================] - 19s 151ms/step - loss: 0.3785 - accuracy: 0.8758
Epoch 7/20
127/127 [==============================] - 20s 161ms/step - loss: 0.2933 - accuracy: 0.9040
Epoch 8/20
127/127 [==============================] - 18s 145ms/step - loss: 0.2567 - accuracy: 0.9195
Epoch 9/20
127/127 [==============================] - 17s 133ms/step - loss: 0.2207 - accuracy: 0.9292
Epoch 10/20
127/127 [==============================] - 17s 134ms/step - loss: 0.1864 - accuracy: 0.9404
Epoch 11/20
127/127 [==============================] - 17s 133ms/step - loss: 0.1923 - accuracy: 0.9417
Epoch 12/20
127/127 [==============================] - 17s 134ms/step - loss: 0.1826 - accuracy: 0.9440
Epoch 13/20
127/127 [==============================] - 17s 133ms/step - loss: 0.1555 - accuracy: 0.9505
Epoch 14/20
127/127 [==============================] - 17s 133ms/step - loss: 0.1309 - accuracy: 0.9624
Epoch 15/20
127/127 [==============================] - 17s 133ms/step - loss: 0.1197 - accuracy: 0.9646
Epoch 16/20
127/127 [==============================] - 17s 133ms/step - loss: 0.1107 - accuracy: 0.9638
Epoch 17/20
127/127 [==============================] - 17s 133ms/step - loss: 0.0944 - accuracy: 0.9711
Epoch 18/20
127/127 [==============================] - 17s 133ms/step - loss: 0.0962 - accuracy: 0.9705
Epoch 19/20
127/127 [==============================] - 17s 133ms/step - loss: 0.0867 - accuracy: 0.9738
Epoch 20/20
127/127 [==============================] - 17s 133ms/step - loss: 0.0958 - accuracy: 0.9730
128/128 [==============================] - 2s 16ms/step - loss: 0.0906 - accuracy: 0.9805
Accuracy: 98.05
Data collection time:  1332.1926 s
Training time:  391.5208 s
Testing time:  0.0 s